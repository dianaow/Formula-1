{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from sympy import S, symbols\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A host of Scikit-learn models\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, accuracy_score, precision_score, average_precision_score, \\\n",
    "classification_report, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_pickle(directory, filename):\n",
    "    df = pd.DataFrame()\n",
    "    filepath = directory + filename\n",
    "    with open(filepath, 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = '/Users/dianaow/Documents/formula-1-race-data/dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = 12\n",
    "njobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initiate tuned sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of tuned classifiers to test:', 16)\n"
     ]
    }
   ],
   "source": [
    "all_tuned_classifiers = read_from_pickle(directory, \"all_tuned_classifiers.pickle\")\n",
    "print(\"Total number of tuned classifiers to test:\", len(all_tuned_classifiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=rs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilize only the Extra Trees Classifiers\n",
    "ExtCs = all_tuned_classifiers[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "\n",
    "    return all_tuned_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners = get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define a meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_learner = ['XGBoost', XGBClassifier(seed = rs, n_estimators=1000, learning_rate=0.1, max_depth=3, min_child_weight=1, gamma=0.0, \\\n",
    "                     subsample=0.5, colsample_bytree=0.5, reg_alpha= 1e-05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get train-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, scaler):\n",
    "    \n",
    "    if scaler == 'StandardScaler':\n",
    "        SS = StandardScaler()\n",
    "        Xs_train = SS.fit_transform(X_train)\n",
    "        Xs_test = SS.fit_transform(X_test)\n",
    "    elif scaler == 'MinMaxScaler':\n",
    "        mm = MinMaxScaler()\n",
    "        Xs_train = mm.fit_transform(X_train)\n",
    "        Xs_test = mm.fit_transform(X_test)  \n",
    "    elif scaler == False:\n",
    "        Xs_train = X_train\n",
    "        Xs_test = X_test\n",
    "        \n",
    "    return Xs_train, Xs_test\n",
    "\n",
    "def build_train_test_set(df, df_test, train_yr, test_yr, index_list, target_var, target_var_list, scaler, \\\n",
    "                         name=None, races_curr_same_cat=None, races_same_cat=None, \\\n",
    "                         zV_nzV_check=False, VIF_check=False, multilabel=False, print_stats=False):\n",
    "    \n",
    "    \"\"\"\n",
    "       Capabilites of this function:\n",
    "       1) Splits dataset to a train and test set and allows for a single or multiple target variables. \n",
    "       2) 2 methods of train-test split\n",
    "           Approach 1: Train-test split by year (set all_races=None)\n",
    "               - This is not a viable options if model includes features that are only known pre-race. eg drivers' selected tyre sets and qualifying position)\n",
    "           Approach 2: Train-test split by races\n",
    "       3) Check for multi-collinearity and features with Zero Variance (important for linear/ordinal regression)\n",
    "       \n",
    "       Notes:\n",
    "       - If multilabel=True, input 'target_var' and 'target_var_list' as the same variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    if zV_nzV_check==True:\n",
    "        non_zero_nz_Var = zV_nzV_filter(df, index_list, target_var_list)\n",
    "        df = df[non_zero_nz_Var]\n",
    "        df_test = df_test[non_zero_nz_Var]\n",
    "\n",
    "    if VIF_check==True:\n",
    "        features_vif_below10 = VIF_filter(df, index_list, target_var_list)\n",
    "        df = df[features_vif_below10]\n",
    "        df_test = df_test[features_vif_below10]\n",
    "        \n",
    "    # =============================================================================================\n",
    "    # BUILD TRAIN AND TEST SET\n",
    "    train_set = df[df['year'].isin(train_yr)].reset_index(drop=True)\n",
    "    \n",
    "    if name != None:\n",
    "\n",
    "        train_set = train_set[train_set['name'].isin(races_same_cat['name'])]\n",
    "        target_ibdex = races_curr_same_cat.index(name)\n",
    "        races_before = races_curr_same_cat[:target_ibdex]\n",
    "        addto_train_set = df[(df['year'].isin(test_yr)) & (df['name'].isin(races_before))].reset_index(drop=True)\n",
    "        train_set = train_set.append(addto_train_set)\n",
    "            \n",
    "        test_set = df_test[df_test['name'] == name].reset_index(drop=True)\n",
    "    \n",
    "    elif (name == None) & (races_same_cat == None) & (races_curr_same_cat == None):\n",
    "        test_set = df_test\n",
    "        \n",
    "    # Separate index, features and target variable\n",
    "    arr = []\n",
    "    arr = list(index_list)\n",
    "    arr_tar_tvar = list(target_var_list)\n",
    "    arr.extend(arr_tar_tvar)\n",
    "    learning_columns = np.setdiff1d(train_set.columns, np.array(arr))\n",
    "    X_train = train_set.loc[:, learning_columns]\n",
    "    X_test = test_set.loc[:, learning_columns]\n",
    "\n",
    "    if multilabel==True:\n",
    "        Y_train = train_set[target_var_list]\n",
    "        Y_test = test_set[target_var_list]\n",
    "        # Ensure target variables are in integers as alogrithms will throw an error otherwise\n",
    "        Y_train = Y_train.apply(lambda x: x.astype(int)) # Dataframe\n",
    "        Y_test = Y_test.apply(lambda x: x.astype(int))\n",
    "    else:\n",
    "        Y_train = train_set[target_var]\n",
    "        Y_test = test_set[target_var]\n",
    "        Y_train = Y_train.astype(int) # Series\n",
    "        Y_test = Y_test.astype(int)\n",
    "        \n",
    "    # =============================================================================================\n",
    "    # Standard scale the dataset after train-test split\n",
    "    Xs_train, Xs_test = scale_data(X_train, X_test, scaler)\n",
    "        \n",
    "    # =============================================================================================\n",
    "    # PRINT STATISTICS (because multilabel option will generate a dataframe, whereas a single target variable results in a series,\n",
    "    # to print statistics, different methods apply...)\n",
    "    \n",
    "    if (multilabel==True) & (print_stats==True):\n",
    "        print '=================================='\n",
    "        print 'Race:', name\n",
    "        print '=================================='\n",
    "\n",
    "        print 'Train set:' + str(len(Y_train))\n",
    "        print '---------------------------------'\n",
    "        print 'Shape of Train Set: ', Xs_train.shape\n",
    "        print Y_train.apply(pd.value_counts).fillna(0)\n",
    "\n",
    "        print '=================================='\n",
    "        print 'Test set: ' + str(len(Y_test))\n",
    "        print '---------------------------------'\n",
    "        print 'Shape of Test Set: ', Xs_test.shape\n",
    "        test_vc = Y_test.apply(pd.value_counts).fillna(0)\n",
    "        print test_vc\n",
    "\n",
    "    elif (multilabel==False) & (print_stats==True):\n",
    "        print '=================================='\n",
    "        print 'Race:', name\n",
    "        print '=================================='\n",
    "\n",
    "        print 'Train set:' + str(Y_train.count())\n",
    "        print '---------------------------------'\n",
    "        print 'Shape of Train Set: ', Xs_train.shape\n",
    "        print Y_train.value_counts() \n",
    "\n",
    "        print '=================================='\n",
    "        print 'Test set: ' + str(Y_test.count())\n",
    "        print '---------------------------------'\n",
    "        print 'Shape of Test Set: ', Xs_test.shape\n",
    "        print Y_test.value_counts() \n",
    "\n",
    "    return train_set, test_set, Xs_train, Xs_test, np.array(Y_train).ravel(), np.array(Y_test).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the base learners on a training set (xtrain_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out, verbose=True):\n",
    "    \"\"\"Train all base learners in the library.\"\"\"\n",
    "\n",
    "    for m in base_learners:\n",
    "        m[1].fit(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5: Generate base learner predictions (Input: xpred_base, output: P_base)\n",
    "- P_base is a matrix of predictions (n_samles, n_base_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_learners(pred_base_learners, inp, verbose=True):\n",
    "    \"\"\"Generate a prediction matrix.\"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "\n",
    "    for i,m in enumerate(pred_base_learners):\n",
    "        p = m[1].predict_proba(inp)\n",
    "        # With two classes, need only predictions for one class\n",
    "        P[:, i] = p[:, 1]\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Use the base predictions to train the meta learner (Input: P_pred, ypred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n",
    "    \"\"\"Generate predictions from the ensemble.\"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict(P_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training base learners with cross-validation\n",
    "- Stacking: Fitting an ensemble with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(base_learners, meta_learner, df, df_test, train_yr, test_yr, index_list, target_var_list, \\\n",
    "             scaler, generator, races_curr_same_cat, races_same_cat):\n",
    "    \n",
    "    \"\"\"Simple training routine for stacking.\"\"\"\n",
    "\n",
    "    P_pred_all = pd.DataFrame()\n",
    "    p_all =  pd.DataFrame()\n",
    "    results_all = pd.DataFrame()\n",
    "    \n",
    "    for race in races_curr_same_cat:\n",
    "        # Step 3: \n",
    "        train_set, test_set, Xs_train, Xs_test, Y_train, Y_test  = \\\n",
    "        build_train_test_set(df, df_test, train_yr, test_yr, index_list, target_var_list, target_var_list, scaler, \\\n",
    "                             race, races_curr_same_cat, races_same_cat, \\\n",
    "                             zV_nzV_check=False, VIF_check=False, multilabel=False, print_stats=False)\n",
    "\n",
    "        # Step 4: Train final base learners for test time\n",
    "        #print(\"Fitting final base learners...\")\n",
    "        train_base_learners(base_learners, Xs_train, Y_train, verbose=False)\n",
    "        #print(\"done\")\n",
    "\n",
    "        # Step 5: Generate predictions for training meta learners\n",
    "        # Outer loop:\n",
    "        #print(\"Generating cross-validated predictions...\")\n",
    "        cv_preds, cv_y = [], []\n",
    "        for i, (train_idx, test_idx) in enumerate(generator.split(Xs_train, Y_train)):\n",
    "\n",
    "            fold_xtrain, fold_ytrain = Xs_train[train_idx, :], Y_train[train_idx]\n",
    "            fold_xtest, fold_ytest = Xs_train[test_idx, :], Y_train[test_idx]\n",
    "\n",
    "            # Inner loop: step 4 and 5\n",
    "            fold_base_learners = [[model[0], clone(model[1])] for model in base_learners]\n",
    "            train_base_learners(fold_base_learners, fold_xtrain, fold_ytrain, verbose=False)\n",
    "\n",
    "            fold_P_base = predict_base_learners(fold_base_learners, fold_xtest, verbose=False)\n",
    "\n",
    "            cv_preds.append(fold_P_base)\n",
    "            cv_y.append(fold_ytest)\n",
    "            #print(\"Fold %i done\" % (i + 1))\n",
    "\n",
    "        #print(\"CV-predictions done\")\n",
    "\n",
    "        # Be careful to get rows in the right order\n",
    "        cv_preds = np.vstack(cv_preds)\n",
    "        cv_y = np.hstack(cv_y)\n",
    "\n",
    "        # Step 5: Train meta learner\n",
    "        #print(\"Fitting meta learner...\")\n",
    "        meta_learner[1].fit(cv_preds, cv_y)\n",
    "        #print(\"done\")\n",
    "        \n",
    "        # Step 6: Use the base predictions to train the meta learner\n",
    "        P_pred, p = ensemble_predict(base_learners, meta_learner[1], Xs_test, verbose=False)\n",
    "        \n",
    "        P_pred_all = pd.concat([P_pred_all, pd.DataFrame(P_pred)])\n",
    "        p_all = pd.concat([p_all, pd.DataFrame(p, columns=[race])], axis=1)\n",
    "\n",
    "        # Step 7: Evaluate prediction results\n",
    "        results_stats  = calc_classification_stats(race, target_var_list, meta_learner[0], \"\", Y_test, p, average=None)\n",
    "        results_all = pd.concat([results_all, results_stats])\n",
    "        \n",
    "    return results_all, P_pred_all, p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_classification_stats(name, target_var, classifier, sampler, y_test, y_pred, average):\n",
    "\n",
    "    # Initiate lists for storing results\n",
    "    recall = []\n",
    "    precision = []\n",
    "    baseline_accuracy = []\n",
    "    test_accuracy = []\n",
    "    f1 = []\n",
    "    avg_precision = []\n",
    "    \n",
    "    #recall.append(recall_score(y_test, y_pred, average=None))\n",
    "    #precision.append(precision_score(y_test, y_pred, average=None))\n",
    "    baseline_accuracy.append(float(pd.Series(y_test).value_counts().max()) / pd.Series(y_test).count())\n",
    "    test_accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    avg_precision.append(average_precision_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred, average=None)) \n",
    "\n",
    "    results_stats = pd.DataFrame({'Index': str(name), 'Target Var': str(target_var), 'Method': classifier, 'Resampler':sampler,\\\n",
    "                                  'Avg Precision': avg_precision, 'F1 Score': f1, 'Test accuracy': test_accuracy, \\\n",
    "                                  'Baseline accuracy': baseline_accuracy})\n",
    "\n",
    "    results_stats = results_stats[['Index', 'Target Var', 'Method', 'Resampler', \"Baseline accuracy\", \"Test accuracy\", 'F1 Score', 'Avg Precision']]\n",
    "\n",
    "    return results_stats  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile(\"/Users/dianaow/Downloads/F1_Tyre_data.xlsx\")\n",
    "xl.sheet_names\n",
    "pirelli = xl.parse(\"Sheet7\")\n",
    "races_dict = pirelli[['year', 'name']].to_dict('list')\n",
    "\n",
    "df_races = read_from_pickle(directory, \"df_races.pickle\")\n",
    "races15 = list(df_races[df_races['year'] == 2015].name.unique())\n",
    "races = list(df_races[df_races['year'] == 2017].name.unique())\n",
    "\n",
    "index_list = ['year', 'driverRef', 'name']\n",
    "target_var_list = ['statusId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_dataset_train = read_from_pickle(directory, \"status_dataset_train.pickle\")\n",
    "status_dataset_test = read_from_pickle(directory, \"status_dataset_test.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) XGBoost as the meta-leaner with all 16 classifiers (4 from each type of classifier: Extra Trees, Random Forest, Gradient Boosting, MLP) as the base-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ExtraTrees0',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=11, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=14,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['ExtraTrees1',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=11, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['ExtraTrees2',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=11, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=14,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['ExtraTrees3',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=13, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=18,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['RandomForest4',\n",
       "  RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=2, min_samples_split=14,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "              oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['RandomForest5',\n",
       "  RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=9, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=2, min_samples_split=6,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "              oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['RandomForest6',\n",
       "  RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=9, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "              oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['RandomForest7',\n",
       "  RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=7, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "              oob_score=False, random_state=12, verbose=0, warm_start=False)],\n",
       " ['GradientBoosting8',\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='deviance', max_depth=None,\n",
       "                max_features=9, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=2, min_samples_split=2,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                presort='auto', random_state=12, subsample=1.0, verbose=0,\n",
       "                warm_start=False)],\n",
       " ['GradientBoosting9',\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='deviance', max_depth=None,\n",
       "                max_features=13, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=2, min_samples_split=6,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                presort='auto', random_state=12, subsample=1.0, verbose=0,\n",
       "                warm_start=False)],\n",
       " ['GradientBoosting10',\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='deviance', max_depth=None,\n",
       "                max_features=11, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=2, min_samples_split=10,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                presort='auto', random_state=12, subsample=1.0, verbose=0,\n",
       "                warm_start=False)],\n",
       " ['GradientBoosting11',\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='deviance', max_depth=None,\n",
       "                max_features=9, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=2, min_samples_split=2,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                presort='auto', random_state=12, subsample=1.0, verbose=0,\n",
       "                warm_start=False)],\n",
       " ['MLP12',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(8,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=12, shuffle=True,\n",
       "         solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False)],\n",
       " ['MLP13',\n",
       "  MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(8,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=12, shuffle=True,\n",
       "         solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False)],\n",
       " ['MLP14',\n",
       "  MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "         beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(7,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=12, shuffle=True,\n",
       "         solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False)],\n",
       " ['MLP15',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(11, 11), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=12, shuffle=True,\n",
       "         solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False)]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Target Var</th>\n",
       "      <th>Method</th>\n",
       "      <th>Resampler</th>\n",
       "      <th>Baseline accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.571428571429, 0.903225806452]</td>\n",
       "      <td>0.869298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.4, 0.8]</td>\n",
       "      <td>0.701584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Index    Target Var   Method Resampler  Baseline accuracy  \\\n",
       "0  Chinese Grand Prix  ['statusId']  XGBoost                     0.789474   \n",
       "0  Bahrain Grand Prix  ['statusId']  XGBoost                     0.650000   \n",
       "\n",
       "   Test accuracy                          F1 Score  Avg Precision  \n",
       "0       0.842105  [0.571428571429, 0.903225806452]       0.869298  \n",
       "0       0.700000                        [0.4, 0.8]       0.701584  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all[results_all['Test accuracy'] > results_all['Baseline accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Target Var</th>\n",
       "      <th>Method</th>\n",
       "      <th>Resampler</th>\n",
       "      <th>Baseline accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>[0.222222222222, 0.758620689655]</td>\n",
       "      <td>0.645769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.571428571429, 0.903225806452]</td>\n",
       "      <td>0.869298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.4, 0.8]</td>\n",
       "      <td>0.701584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[0.0, 0.787878787879]</td>\n",
       "      <td>0.771324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanish Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[0.222222222222, 0.774193548387]</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monaco Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>[0.0, 0.733333333333]</td>\n",
       "      <td>0.652774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canadian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.4, 0.8]</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azerbaijan Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[0.333333333333, 0.714285714286]</td>\n",
       "      <td>0.662821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[0.333333333333, 0.882352941176]</td>\n",
       "      <td>0.831250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>British Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.0, 0.823529411765]</td>\n",
       "      <td>0.828201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hungarian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.25, 0.8]</td>\n",
       "      <td>0.853383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.0, 0.823529411765]</td>\n",
       "      <td>0.780556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.444444444444, 0.838709677419]</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[0.2, 0.733333333333]</td>\n",
       "      <td>0.610185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malaysian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[0.0, 0.888888888889]</td>\n",
       "      <td>0.890123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>[0.2, 0.714285714286]</td>\n",
       "      <td>0.720730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>[0.285714285714, 0.838709677419]</td>\n",
       "      <td>0.809430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mexican Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.0, 0.8125]</td>\n",
       "      <td>0.768008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>[0.0, 0.848484848485]</td>\n",
       "      <td>0.825851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.0, 0.8125]</td>\n",
       "      <td>0.873271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Index    Target Var   Method Resampler  \\\n",
       "0     Australian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Chinese Grand Prix  ['statusId']  XGBoost             \n",
       "0        Bahrain Grand Prix  ['statusId']  XGBoost             \n",
       "0        Russian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Spanish Grand Prix  ['statusId']  XGBoost             \n",
       "0         Monaco Grand Prix  ['statusId']  XGBoost             \n",
       "0       Canadian Grand Prix  ['statusId']  XGBoost             \n",
       "0     Azerbaijan Grand Prix  ['statusId']  XGBoost             \n",
       "0       Austrian Grand Prix  ['statusId']  XGBoost             \n",
       "0        British Grand Prix  ['statusId']  XGBoost             \n",
       "0      Hungarian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Belgian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Italian Grand Prix  ['statusId']  XGBoost             \n",
       "0      Singapore Grand Prix  ['statusId']  XGBoost             \n",
       "0      Malaysian Grand Prix  ['statusId']  XGBoost             \n",
       "0       Japanese Grand Prix  ['statusId']  XGBoost             \n",
       "0  United States Grand Prix  ['statusId']  XGBoost             \n",
       "0        Mexican Grand Prix  ['statusId']  XGBoost             \n",
       "0      Brazilian Grand Prix  ['statusId']  XGBoost             \n",
       "0      Abu Dhabi Grand Prix  ['statusId']  XGBoost             \n",
       "\n",
       "   Baseline accuracy  Test accuracy                          F1 Score  \\\n",
       "0           0.631579       0.631579  [0.222222222222, 0.758620689655]   \n",
       "0           0.789474       0.842105  [0.571428571429, 0.903225806452]   \n",
       "0           0.650000       0.700000                        [0.4, 0.8]   \n",
       "0           0.800000       0.650000             [0.0, 0.787878787879]   \n",
       "0           0.800000       0.650000  [0.222222222222, 0.774193548387]   \n",
       "0           0.684211       0.578947             [0.0, 0.733333333333]   \n",
       "0           0.750000       0.700000                        [0.4, 0.8]   \n",
       "0           0.650000       0.600000  [0.333333333333, 0.714285714286]   \n",
       "0           0.800000       0.800000  [0.333333333333, 0.882352941176]   \n",
       "0           0.850000       0.700000             [0.0, 0.823529411765]   \n",
       "0           0.842105       0.684211                       [0.25, 0.8]   \n",
       "0           0.800000       0.700000             [0.0, 0.823529411765]   \n",
       "0           0.800000       0.750000  [0.444444444444, 0.838709677419]   \n",
       "0           0.600000       0.600000             [0.2, 0.733333333333]   \n",
       "0           0.900000       0.800000             [0.0, 0.888888888889]   \n",
       "0           0.736842       0.578947             [0.2, 0.714285714286]   \n",
       "0           0.789474       0.736842  [0.285714285714, 0.838709677419]   \n",
       "0           0.789474       0.684211                     [0.0, 0.8125]   \n",
       "0           0.842105       0.736842             [0.0, 0.848484848485]   \n",
       "0           0.894737       0.684211                     [0.0, 0.8125]   \n",
       "\n",
       "   Avg Precision  \n",
       "0       0.645769  \n",
       "0       0.869298  \n",
       "0       0.701584  \n",
       "0       0.771324  \n",
       "0       0.800000  \n",
       "0       0.652774  \n",
       "0       0.790000  \n",
       "0       0.662821  \n",
       "0       0.831250  \n",
       "0       0.828201  \n",
       "0       0.853383  \n",
       "0       0.780556  \n",
       "0       0.854167  \n",
       "0       0.610185  \n",
       "0       0.890123  \n",
       "0       0.720730  \n",
       "0       0.809430  \n",
       "0       0.768008  \n",
       "0       0.825851  \n",
       "0       0.873271  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) XGBoost as the meta-leaner with a one selected classifier from the group of various classifiers  as the base-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers_to_filter = ['ExtraTree1', 'RandomForest0','GradientBoosting1', 'MLP0']\n",
    "sel_clfs = [x for x in all_tuned_classifiers if x[0] in classifiers_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_selclfs, P_pred_selclfs, p_selclfs = stacking(sel_clfs, meta_learner, status_dataset_train, status_dataset_test,\\\n",
    "                                            [2016], [2017], index_list, target_var_list, \\\n",
    "                                            'StandardScaler', skfold, races, races_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Target Var</th>\n",
       "      <th>Method</th>\n",
       "      <th>Resampler</th>\n",
       "      <th>Baseline accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.4, 0.909090909091]</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.4, 0.909090909091]</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Index    Target Var   Method Resampler  \\\n",
       "0        Chinese Grand Prix  ['statusId']  XGBoost             \n",
       "0  United States Grand Prix  ['statusId']  XGBoost             \n",
       "\n",
       "   Baseline accuracy  Test accuracy               F1 Score  Avg Precision  \n",
       "0           0.789474       0.842105  [0.4, 0.909090909091]       0.833333  \n",
       "0           0.789474       0.842105  [0.4, 0.909090909091]       0.833333  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_selclfs[results_selclfs['Test accuracy'] > results_selclfs['Baseline accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Target Var</th>\n",
       "      <th>Method</th>\n",
       "      <th>Resampler</th>\n",
       "      <th>Baseline accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[0.181818181818, 0.666666666667]</td>\n",
       "      <td>0.607895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.4, 0.909090909091]</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[0.222222222222, 0.774193548387]</td>\n",
       "      <td>0.665385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[0.166666666667, 0.642857142857]</td>\n",
       "      <td>0.771875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanish Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.0, 0.857142857143]</td>\n",
       "      <td>0.790132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monaco Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>[0.0, 0.642857142857]</td>\n",
       "      <td>0.625911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canadian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[0.333333333333, 0.714285714286]</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azerbaijan Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>[0.181818181818, 0.689655172414]</td>\n",
       "      <td>0.630769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[0.222222222222, 0.774193548387]</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>British Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[0.333333333333, 0.882352941176]</td>\n",
       "      <td>0.878547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hungarian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>[0.444444444444, 0.827586206897]</td>\n",
       "      <td>0.902834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.0, 0.857142857143]</td>\n",
       "      <td>0.790132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.25, 0.8125]</td>\n",
       "      <td>0.810156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>[0.181818181818, 0.689655172414]</td>\n",
       "      <td>0.590196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malaysian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[0.0, 0.823529411765]</td>\n",
       "      <td>0.880556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.25, 0.8]</td>\n",
       "      <td>0.748120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.4, 0.909090909091]</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mexican Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.0, 0.8125]</td>\n",
       "      <td>0.768008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>[0.0, 0.8125]</td>\n",
       "      <td>0.818051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>['statusId']</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td></td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>[0.0, 0.848484848485]</td>\n",
       "      <td>0.878483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Index    Target Var   Method Resampler  \\\n",
       "0     Australian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Chinese Grand Prix  ['statusId']  XGBoost             \n",
       "0        Bahrain Grand Prix  ['statusId']  XGBoost             \n",
       "0        Russian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Spanish Grand Prix  ['statusId']  XGBoost             \n",
       "0         Monaco Grand Prix  ['statusId']  XGBoost             \n",
       "0       Canadian Grand Prix  ['statusId']  XGBoost             \n",
       "0     Azerbaijan Grand Prix  ['statusId']  XGBoost             \n",
       "0       Austrian Grand Prix  ['statusId']  XGBoost             \n",
       "0        British Grand Prix  ['statusId']  XGBoost             \n",
       "0      Hungarian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Belgian Grand Prix  ['statusId']  XGBoost             \n",
       "0        Italian Grand Prix  ['statusId']  XGBoost             \n",
       "0      Singapore Grand Prix  ['statusId']  XGBoost             \n",
       "0      Malaysian Grand Prix  ['statusId']  XGBoost             \n",
       "0       Japanese Grand Prix  ['statusId']  XGBoost             \n",
       "0  United States Grand Prix  ['statusId']  XGBoost             \n",
       "0        Mexican Grand Prix  ['statusId']  XGBoost             \n",
       "0      Brazilian Grand Prix  ['statusId']  XGBoost             \n",
       "0      Abu Dhabi Grand Prix  ['statusId']  XGBoost             \n",
       "\n",
       "   Baseline accuracy  Test accuracy                          F1 Score  \\\n",
       "0           0.631579       0.526316  [0.181818181818, 0.666666666667]   \n",
       "0           0.789474       0.842105             [0.4, 0.909090909091]   \n",
       "0           0.650000       0.650000  [0.222222222222, 0.774193548387]   \n",
       "0           0.800000       0.500000  [0.166666666667, 0.642857142857]   \n",
       "0           0.800000       0.750000             [0.0, 0.857142857143]   \n",
       "0           0.684211       0.473684             [0.0, 0.642857142857]   \n",
       "0           0.750000       0.600000  [0.333333333333, 0.714285714286]   \n",
       "0           0.650000       0.550000  [0.181818181818, 0.689655172414]   \n",
       "0           0.800000       0.650000  [0.222222222222, 0.774193548387]   \n",
       "0           0.850000       0.800000  [0.333333333333, 0.882352941176]   \n",
       "0           0.842105       0.736842  [0.444444444444, 0.827586206897]   \n",
       "0           0.800000       0.750000             [0.0, 0.857142857143]   \n",
       "0           0.800000       0.700000                    [0.25, 0.8125]   \n",
       "0           0.600000       0.550000  [0.181818181818, 0.689655172414]   \n",
       "0           0.900000       0.700000             [0.0, 0.823529411765]   \n",
       "0           0.736842       0.684211                       [0.25, 0.8]   \n",
       "0           0.789474       0.842105             [0.4, 0.909090909091]   \n",
       "0           0.789474       0.684211                     [0.0, 0.8125]   \n",
       "0           0.842105       0.684211                     [0.0, 0.8125]   \n",
       "0           0.894737       0.736842             [0.0, 0.848484848485]   \n",
       "\n",
       "   Avg Precision  \n",
       "0       0.607895  \n",
       "0       0.833333  \n",
       "0       0.665385  \n",
       "0       0.771875  \n",
       "0       0.790132  \n",
       "0       0.625911  \n",
       "0       0.762821  \n",
       "0       0.630769  \n",
       "0       0.800000  \n",
       "0       0.878547  \n",
       "0       0.902834  \n",
       "0       0.790132  \n",
       "0       0.810156  \n",
       "0       0.590196  \n",
       "0       0.880556  \n",
       "0       0.748120  \n",
       "0       0.833333  \n",
       "0       0.768008  \n",
       "0       0.818051  \n",
       "0       0.878483  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_selclfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of results:\n",
    "- 2 out of 20 races in 2017 season achieved predicion accuracy above baseline using XGBoost Classifier as the meta-learner with Ensemble Stacking.\n",
    "- Narrowing down base-learners did not improve on prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
